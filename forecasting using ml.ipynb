{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOG9VdgYLt5X70+dBhpwGiT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Badal3000/Badal3000/blob/main/forecasting%20using%20ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forecasting with machine learning"
      ],
      "metadata": {
        "id": "1PGhs5OJWQex"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "QduDiSmwWPgp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "keras = tf.keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_series(time, series, format=\"-\", start = 0, end = None, label  = None):\n",
        "  plt.plot(time[start:end], series[start:end], format, label = label)\n",
        "  plt.xlabel(\"Time\")\n",
        "  plt.ylabel(\"value\")\n",
        "  if label:\n",
        "    plt.legend(fontsize = 14)\n",
        "  plt.grid(True)\n",
        "\n",
        "  def trend(time, slope = 0):\n",
        "    return slope*time\n",
        "\n",
        "  def seasonal_pattern(season_time):\n",
        "    return np.where(season_time < 0.4,\n",
        "                    np.cos(season_time * 2 * np.pi),\n",
        "                    1 / np.exp(3 * season_time))\n",
        "\n",
        "  def seasonality(time, period, amplitude=1, phase=0):\n",
        "    season_time = ((time + phase) % period) / period\n",
        "    return amplitude * seasonal_pattern(season_time)\n",
        "\n",
        "  def white_noise(time, noise_level = 1, seed = None):\n",
        "    rnd = np.random.RandomState(seed)\n",
        "    return rnd.randn(len(time)) * noise_level"
      ],
      "metadata": {
        "id": "AEKOHohFWVW4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time = np.arange(4 * 365 + 1)\n",
        "\n",
        "sloppe = 0.05\n",
        "baseline = 10\n",
        "amplitude = 40\n",
        "series = baseline + trend(time, slope) + seasonality(time, period=365, amplitude=amplitude)\n",
        "\n",
        "noise_level = 5\n",
        "noise = white_noise(time, noise_level, seed = 42)\n",
        "\n",
        "series+= noise\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plot_series(time, series)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "h7vvJdgJWVZh",
        "outputId": "59fdae32-b808-40d3-bad8-665633a9fc29"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-db11de54fc07>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbaseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mamplitude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslope\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mseasonality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m365\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamplitude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamplitude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnoise_level\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trend' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def window_dataset(series, window_size, batch_size=32,\n",
        "                   shuffle_buffer=1000):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
        "    dataset = dataset.shuffle(shuffle_buffer)\n",
        "    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
        "    dataset = dataset.batch(batch_size).prefetch(1)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "mAn_zbYZWVb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_time = 1000\n",
        "time_train = time[:split_time]\n",
        "x_train = series[:split_time]\n",
        "time_valid = time[split_time:]\n",
        "x_valid = series[split_time:]"
      ],
      "metadata": {
        "id": "reS1GfBlWVd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "window_size = 30\n",
        "train_set = window_dataset(x_train, window_size)\n",
        "valid_set = window_dataset(x_valid, window_size)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "  keras.layers.Dense(1, input_shape=[window_size])\n",
        "])\n",
        "optimizer = keras.optimizers.SGD(lr=1e-5, momentum=0.9)\n",
        "model.compile(loss=keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])\n",
        "model.fit(train_set, epochs=100, validation_data=valid_set)"
      ],
      "metadata": {
        "id": "p_2e2lVSWVgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "window_size = 30\n",
        "train_set = window_dataset(x_train, window_size)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "  keras.layers.Dense(1, input_shape=[window_size])\n",
        "])\n",
        "\n",
        "lr_schedule = keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: 1e-6 * 10**(epoch / 30))\n",
        "optimizer = keras.optimizers.SGD(lr=1e-6, momentum=0.9)\n",
        "model.compile(loss=keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])\n",
        "history = model.fit(train_set, epochs=100, callbacks=[lr_schedule])"
      ],
      "metadata": {
        "id": "h8K9RsmHWVia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
        "plt.axis([1e-6, 1e-3, 0, 20])"
      ],
      "metadata": {
        "id": "tO0JL7uvWVkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "window_size = 30\n",
        "train_set = window_dataset(x_train, window_size)\n",
        "valid_set = window_dataset(x_valid, window_size)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "  keras.layers.Dense(1, input_shape=[window_size])\n",
        "])\n",
        "optimizer = keras.optimizers.SGD(lr=1e-5, momentum=0.9)\n",
        "model.compile(loss=keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])\n",
        "early_stopping = keras.callbacks.EarlyStopping(patience=10)\n",
        "model.fit(train_set, epochs=500,\n",
        "          validation_data=valid_set,\n",
        "          callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "u9lh8cPvWVnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_forecast(model, series, window_size):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "    ds = ds.window(window_size, shift=1, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda w: w.batch(window_size))\n",
        "    ds = ds.batch(32).prefetch(1)\n",
        "    forecast = model.predict(ds)\n",
        "    return forecast"
      ],
      "metadata": {
        "id": "N8WOzF4eWVpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_forecast(model, series, window_size):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "    ds = ds.window(window_size, shift=1, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda w: w.batch(window_size))\n",
        "    ds = ds.batch(32).prefetch(1)\n",
        "    forecast = model.predict(ds)\n",
        "    return forecast"
      ],
      "metadata": {
        "id": "z47Mi4oTWVtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lin_forecast.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "Td1JtDZ0WVv7",
        "outputId": "966e18ae-a94f-44bd-8b29-fc378c5fcd73"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-17b7413e6db2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlin_forecast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'lin_forecast' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time_valid, x_valid)\n",
        "plot_series(time_valid, lin_forecast)"
      ],
      "metadata": {
        "id": "4U-aZOuIcjvL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.metrics.mean_absolute_error(x_valid, lin_forecast).numpy()"
      ],
      "metadata": {
        "id": "sBllbQXPcj1L"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "window_size = 30\n",
        "train_set = window_dataset(x_train, window_size)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "  keras.layers.Dense(10, activation=\"relu\", input_shape=[window_size]),\n",
        "  keras.layers.Dense(10, activation=\"relu\"),\n",
        "  keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "lr_schedule = keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: 1e-7 * 10**(epoch / 20))\n",
        "optimizer = keras.optimizers.SGD(lr=1e-7, momentum=0.9)\n",
        "model.compile(loss=keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])\n",
        "history = model.fit(train_set, epochs=100, callbacks=[lr_schedule])"
      ],
      "metadata": {
        "id": "rMb59e3mcj4j"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
        "plt.axis([1e-7, 5e-3, 0, 30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "l2WqYC29cj72",
        "outputId": "e36b3375-538b-4d2e-8963-ab2a859cc0ed"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-52b2aace47c3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msemilogx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "window_size = 30\n",
        "train_set = window_dataset(x_train, window_size)\n",
        "valid_set = window_dataset(x_valid, window_size)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "  keras.layers.Dense(10, activation=\"relu\", input_shape=[window_size]),\n",
        "  keras.layers.Dense(10, activation=\"relu\"),\n",
        "  keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "optimizer = keras.optimizers.SGD(lr=1e-5, momentum=0.9)\n",
        "model.compile(loss=keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])\n",
        "early_stopping = keras.callbacks.EarlyStopping(patience=10)\n",
        "model.fit(train_set, epochs=500,\n",
        "          validation_data=valid_set,\n",
        "          callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "aNaZDmW2ctu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dense_forecast = model_forecast(\n",
        "    model,\n",
        "    series[split_time - window_size:-1],\n",
        "    window_size)[:, 0]"
      ],
      "metadata": {
        "id": "Fa6gUgJKct0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time_valid, x_valid)\n",
        "plot_series(time_valid, dense_forecast)"
      ],
      "metadata": {
        "id": "SEyo3tc6ct35"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.metrics.mean_absolute_error(x_valid, dense_forecast).numpy()"
      ],
      "metadata": {
        "id": "a-mx4-w6ct7w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}